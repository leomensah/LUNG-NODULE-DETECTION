{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNET PLUS WITH AUGMENTATION.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1Sc454FKCoznr9I9uiTv7Qc5-GyWzC6Le",
      "authorship_tag": "ABX9TyNc7iSbVreBb4vO4unh4rnr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leomensah/LUNG-NODULE-DETECTION/blob/main/UNET_PLUS_WITH_AUGMENTATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Bs2bFhTFRE5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b306dc5c-7f36-4a9c-b92a-b28afd6d4580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations==0.4.6"
      ],
      "metadata": {
        "id": "Q8W2sGndQpmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1fb4d8e-5d9f-4f41-d997-142eb54bccc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Collecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 28.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.1.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.7)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65174 sha256=a8f467d519b458ee96520afea4b1039d6e58f2190d880b3f86cac1f1fd302e3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class VGGBlock(nn.Module):\n",
        "    def __init__(self, in_channels, middle_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_channels, middle_channels, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(middle_channels)\n",
        "        self.conv2 = nn.Conv2d(middle_channels, out_channels, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class NestedUNet(nn.Module):\n",
        "    def __init__(self, num_classes, input_channels=1,  **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        nb_filter = [32, 64, 128, 256, 512]\n",
        "\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.conv0_0 = VGGBlock(input_channels, nb_filter[0], nb_filter[0])\n",
        "        self.conv1_0 = VGGBlock(nb_filter[0], nb_filter[1], nb_filter[1])\n",
        "        self.conv2_0 = VGGBlock(nb_filter[1], nb_filter[2], nb_filter[2])\n",
        "        self.conv3_0 = VGGBlock(nb_filter[2], nb_filter[3], nb_filter[3])\n",
        "        self.conv4_0 = VGGBlock(nb_filter[3], nb_filter[4], nb_filter[4])\n",
        "\n",
        "        self.conv0_1 = VGGBlock(nb_filter[0]+nb_filter[1], nb_filter[0], nb_filter[0])\n",
        "        self.conv1_1 = VGGBlock(nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])\n",
        "        self.conv2_1 = VGGBlock(nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])\n",
        "        self.conv3_1 = VGGBlock(nb_filter[3]+nb_filter[4], nb_filter[3], nb_filter[3])\n",
        "\n",
        "        self.conv0_2 = VGGBlock(nb_filter[0]*2+nb_filter[1], nb_filter[0], nb_filter[0])\n",
        "        self.conv1_2 = VGGBlock(nb_filter[1]*2+nb_filter[2], nb_filter[1], nb_filter[1])\n",
        "        self.conv2_2 = VGGBlock(nb_filter[2]*2+nb_filter[3], nb_filter[2], nb_filter[2])\n",
        "\n",
        "        self.conv0_3 = VGGBlock(nb_filter[0]*3+nb_filter[1], nb_filter[0], nb_filter[0])\n",
        "        self.conv1_3 = VGGBlock(nb_filter[1]*3+nb_filter[2], nb_filter[1], nb_filter[1])\n",
        "\n",
        "        self.conv0_4 = VGGBlock(nb_filter[0]*4+nb_filter[1], nb_filter[0], nb_filter[0])\n",
        "\n",
        "\n",
        "        self.final = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        x0_0 = self.conv0_0(input)\n",
        "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
        "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n",
        "\n",
        "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
        "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n",
        "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n",
        "\n",
        "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
        "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n",
        "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n",
        "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n",
        "\n",
        "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
        "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n",
        "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n",
        "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n",
        "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n",
        "\n",
        "        output = self.final(x0_4)\n",
        "        return output"
      ],
      "metadata": {
        "id": "M0gO1YM7Pk0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iou_score(output, target):\n",
        "    smooth = 1e-5\n",
        "\n",
        "    if torch.is_tensor(output):\n",
        "        output = torch.sigmoid(output).data.cpu().numpy()\n",
        "    if torch.is_tensor(target):\n",
        "        target = target.data.cpu().numpy()\n",
        "    output_ = output > 0.5\n",
        "    target_ = target > 0.5\n",
        "    intersection = (output_ & target_).sum()\n",
        "    union = (output_ | target_).sum()\n",
        "\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "def dice_coef(output, target):\n",
        "    smooth = 1e-5\n",
        "\n",
        "    # we need to use sigmoid because the output of Unet is logit.\n",
        "    output = torch.sigmoid(output).view(-1).data.cpu().numpy()\n",
        "    target = target.view(-1).data.cpu().numpy()\n",
        "    intersection = (output * target).sum()\n",
        "    \n",
        "\n",
        "    return (2. * intersection + smooth) / (output.sum() + target.sum() + smooth)\n",
        "\n",
        "def dice_coef2(output, target):\n",
        "    \"This metric is for validation purpose\"\n",
        "    smooth = 1e-5\n",
        "\n",
        "    output = output.view(-1)\n",
        "    output = (output>0.5).float().cpu().numpy()\n",
        "    target = target.view(-1).data.cpu().numpy()\n",
        "    intersection = (output * target).sum()\n",
        "    \n",
        "\n",
        "    return (2. * intersection + smooth) / (output.sum() + target.sum() + smooth)\n",
        "def str2bool(v):\n",
        "    if v.lower() in ['true', 1]:\n",
        "        return True\n",
        "    elif v.lower() in ['false', 0]:\n",
        "        return False\n",
        "\n",
        "def count_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "__all__ = ['BCEDiceLoss']\n",
        "\n",
        "class BCEDiceLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, input, target):\n",
        "    bce = F.binary_cross_entropy_with_logits(input, target)\n",
        "    smooth = 1e-5\n",
        "    input = torch.sigmoid(input)\n",
        "    num = target.size(0)\n",
        "    input = input.view(num, -1)\n",
        "    target = target.view(num, -1)\n",
        "    intersection = (input * target)\n",
        "    dice = (2. * intersection.sum(1) + smooth) / (input.sum(1) + target.sum(1) + smooth)\n",
        "    dice = 1 - dice.sum() / num\n",
        "\n",
        "    return 0.5 * bce + dice"
      ],
      "metadata": {
        "id": "mOyDtK7bPoMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NK6TfUI_PXrC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torchvision.transforms.functional as TF\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import albumentations as albu\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "class MyLidcDataset(Dataset):\n",
        "  def __init__(self, images_paths, mask_paths):\n",
        "    self.image_paths = images_paths\n",
        "    self.mask_paths = mask_paths\n",
        "\n",
        "    self.albu_transformations =  albu.Compose([\n",
        "            albu.ElasticTransform(alpha=1.1,alpha_affine=0.5,sigma=5,p=0.15),\n",
        "            albu.HorizontalFlip(p=0.15),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "    self.transformations = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "  def transform(self, image, mask):\n",
        "    image = image.reshape(512,512,1)\n",
        "    mask = mask.reshape(512,512,1)\n",
        "    mask = mask.astype('uint8')\n",
        "    augmented=  self.albu_transformations(image=image,mask=mask)\n",
        "    image = augmented['image']\n",
        "    mask = augmented['mask']\n",
        "    mask= mask.reshape([1,512,512])\n",
        "    image, mask = image.type(torch.FloatTensor), mask.type(torch.FloatTensor)\n",
        "    return image, mask\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = np.load(self.image_paths[index])\n",
        "    mask = np.load(self.mask_paths[index])\n",
        "    image, mask = self.transform(image, mask)\n",
        "    return image, mask\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_paths)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "import yaml\n",
        "\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer):\n",
        "  avg_meters = {\n",
        "      'loss': AverageMeter(),\n",
        "      'iou': AverageMeter(),\n",
        "      'dice': AverageMeter()\n",
        "  }\n",
        "\n",
        "  model.train()\n",
        "  pbar = tqdm(total=len(train_loader))\n",
        "  for input, target in train_loader:\n",
        "    input = input.cuda()\n",
        "    target = target.cuda()\n",
        "\n",
        "    output = model(input)\n",
        "    loss = criterion(output, target)\n",
        "    iou = iou_score(output, target)\n",
        "    dice = dice_coef(output, target)\n",
        "\n",
        "    # compute gradient and do optimizing step\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_meters['loss'].update(loss.item(), input.size(0))\n",
        "    avg_meters['iou'].update(iou, input.size(0))\n",
        "    avg_meters['dice'].update(dice, input.size(0))\n",
        "\n",
        "    postfix = OrderedDict([\n",
        "            ('loss', avg_meters['loss'].avg),\n",
        "            ('iou', avg_meters['iou'].avg),\n",
        "            ('dice',avg_meters['dice'].avg)\n",
        "        ])\n",
        "    pbar.set_postfix(postfix)\n",
        "    pbar.update(1)\n",
        "  pbar.close()\n",
        "\n",
        "  return OrderedDict([('loss', avg_meters['loss'].avg),\n",
        "                      ('iou', avg_meters['iou'].avg),\n",
        "                      ('dice',avg_meters['dice'].avg)])\n",
        "    \n",
        "def validate(val_loader, model, criterion):\n",
        "\n",
        "  avg_meters = {'loss': AverageMeter(),\n",
        "                'iou': AverageMeter(),\n",
        "                'dice': AverageMeter()}\n",
        "\n",
        "  # Swicth to evaluate mode\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    pbar = tqdm(total=len(val_loader))\n",
        "    for input, target in val_loader:\n",
        "      input = input.cuda()\n",
        "      target = target.cuda()\n",
        "\n",
        "      output = model(input)\n",
        "      loss = criterion(output, target)\n",
        "      iou = iou_score(output, target)\n",
        "      dice = dice_coef(output, target)\n",
        "\n",
        "      avg_meters['loss'].update(loss.item(), input.size(0))\n",
        "      avg_meters['iou'].update(iou, input.size(0))\n",
        "      avg_meters['dice'].update(dice, input.size(0))\n",
        "\n",
        "      postfix = OrderedDict([\n",
        "                ('loss', avg_meters['loss'].avg),\n",
        "                ('iou', avg_meters['iou'].avg),\n",
        "                ('dice',avg_meters['dice'].avg)\n",
        "            ])\n",
        "      pbar.set_postfix(postfix)\n",
        "      pbar.update(1)\n",
        "    pbar.close()\n",
        "  return OrderedDict([('loss', avg_meters['loss'].avg),\n",
        "                        ('iou', avg_meters['iou'].avg),\n",
        "                        ('dice',avg_meters['dice'].avg)])"
      ],
      "metadata": {
        "id": "oW8pXmUxP1a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'UNET_PLUS_AUGMENTATION'\n",
        "\n",
        "os.makedirs('/content/drive/MyDrive/data/output/model_outputs/{}'.format(filename), exist_ok=True)\n",
        "print(\"Creating directory called\", filename)\n",
        "\n",
        "criterion = BCEDiceLoss().cuda()\n",
        "cudnn.benchmark = True\n",
        "\n",
        "# Creating the model\n",
        "print(\"======= MODEL CREATING IN PROGRESS =====\")\n",
        "model = NestedUNet(num_classes=1)\n",
        "model = model.cuda()\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "  print(\"Let's use\", torch.cuda.device_count(), \"GPU\")\n",
        "  model = nn.DataParallel(model)\n",
        "params = filter(lambda p: p.requires_grad, model.parameters())\n",
        "epochs = 50\n",
        "learning_rate = 1e-5\n",
        "weight_decay = 1e-4\n",
        "momentum = 0.9\n",
        "nesterov = False\n",
        "early_stopping = 50\n",
        "optimizer = optim.Adam(params, lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "# Directory of Image, Mask folder generated from the preprocessing stage ###\n",
        "image_dir = '/content/drive/MyDrive/data/Nodule_data/image/'\n",
        "mask_dir = '/content/drive/MyDrive/data/Nodule_data/mask/'\n",
        "meta = pd.read_csv('/content/drive/MyDrive/data/Nodule_data/meta/meta.csv')\n",
        "\n",
        "meta['original_image']= meta['original_image'].apply(lambda x:image_dir+ x +'.npy')\n",
        "meta['mask_image'] = meta['mask_image'].apply(lambda x:mask_dir+ x +'.npy')\n",
        "\n",
        "train_meta = meta[meta['data_split']=='Train']\n",
        "val_meta = meta[meta['data_split']=='Validation']\n",
        "\n",
        "# Get all *npy images into list for Train\n",
        "train_image_paths = list(train_meta['original_image'])\n",
        "train_mask_paths = list(train_meta['mask_image'])\n",
        "\n",
        "# Get all *npy images into list for Validation\n",
        "val_image_paths = list(val_meta['original_image'])\n",
        "val_mask_paths = list(val_meta['mask_image'])\n",
        "\n",
        "print(\"*\"*50)\n",
        "print(\"The length of image: {}, mask folders: {} for train\".format(len(train_image_paths),len(train_mask_paths)))\n",
        "print(\"The length of image: {}, mask folders: {} for validation\".format(len(val_image_paths),len(val_mask_paths)))\n",
        "print(\"Ratio between Val/ Train is {:2f}\".format(len(val_image_paths)/len(train_image_paths)))\n",
        "print(\"*\"*50)\n",
        "\n",
        "# Create Dataset\n",
        "train_dataset = MyLidcDataset(train_image_paths, train_mask_paths)\n",
        "val_dataset = MyLidcDataset(val_image_paths,val_mask_paths)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        "    drop_last=True,\n",
        "    num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=False,\n",
        "    pin_memory=True,\n",
        "    drop_last=False,\n",
        "    num_workers=2)\n",
        "log= pd.DataFrame(index=[],columns= ['epoch','lr','loss','iou','dice','val_loss','val_iou'])\n",
        "\n",
        "best_dice = 0\n",
        "trigger = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # train for one epoch\n",
        "  train_log = train(train_loader, model, criterion, optimizer)\n",
        "  # evaluate on validation set\n",
        "  val_log = validate(val_loader, model, criterion)\n",
        "\n",
        "  print('Training epoch [{}/{}], Training BCE loss:{:.4f}, Training DICE:{:.4f}, Training IOU:{:.4f}, Validation BCE loss:{:.4f}, Validation Dice:{:.4f}, Validation IOU:{:.4f}'.format(\n",
        "        epoch + 1, epochs, train_log['loss'], train_log['dice'], train_log['iou'], val_log['loss'], val_log['dice'],val_log['iou']))\n",
        "  \n",
        "  tmp = pd.Series([\n",
        "      epoch,\n",
        "      learning_rate,\n",
        "      train_log['loss'],\n",
        "      train_log['iou'],\n",
        "      train_log['dice'],\n",
        "      val_log['loss'],\n",
        "      val_log['iou'],\n",
        "      val_log['dice']\n",
        "  ], index=['epoch', 'lr', 'loss', 'iou', 'dice', 'val_loss', 'val_iou','val_dice'])\n",
        "\n",
        "  log = log.append(tmp, ignore_index=True)\n",
        "  log.to_csv('/content/drive/MyDrive/data/output/model_outputs/{}/log.csv'.format(filename), index=False)\n",
        "\n",
        "  trigger += 1\n",
        "\n",
        "  if val_log['dice'] > best_dice:\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/data/output/model_outputs/{}/model.pth'.format(filename))\n",
        "    best_dice = val_log['dice']\n",
        "    print(\"=> saved best model as validation DICE is greater than previous best DICE\")\n",
        "    trigger = 0\n",
        "\n",
        "  torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXXSvTg5QEMq",
        "outputId": "81148270-aac4-4a5e-cd4e-a6788a5b94ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating directory called UNET_PLUS_AUGMENTATION\n",
            "======= MODEL CREATING IN PROGRESS =====\n",
            "**************************************************\n",
            "The length of image: 8349, mask folders: 8349 for train\n",
            "The length of image: 2783, mask folders: 2783 for validation\n",
            "Ratio between Val/ Train is 0.333333\n",
            "**************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [56:36<00:00,  1.23it/s, loss=1.16, iou=0.0863, dice=0.00176]\n",
            "100%|██████████| 1392/1392 [18:15<00:00,  1.27it/s, loss=1.12, iou=0.188, dice=0.00276]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [1/50], Training BCE loss:1.1614, Training DICE:0.0018, Training IOU:0.0863, Validation BCE loss:1.1215, Validation Dice:0.0028, Validation IOU:0.1881\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:47<00:00,  2.00it/s, loss=1.09, iou=0.249, dice=0.00433]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.68it/s, loss=1.07, iou=0.247, dice=0.00522]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [2/50], Training BCE loss:1.0939, Training DICE:0.0043, Training IOU:0.2485, Validation BCE loss:1.0717, Validation Dice:0.0052, Validation IOU:0.2475\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:45<00:00,  2.00it/s, loss=1.05, iou=0.279, dice=0.00792]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.67it/s, loss=1.03, iou=0.259, dice=0.00971]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [3/50], Training BCE loss:1.0510, Training DICE:0.0079, Training IOU:0.2793, Validation BCE loss:1.0348, Validation Dice:0.0097, Validation IOU:0.2589\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:46<00:00,  2.00it/s, loss=1.02, iou=0.278, dice=0.0145]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.68it/s, loss=1.01, iou=0.273, dice=0.0179]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [4/50], Training BCE loss:1.0194, Training DICE:0.0145, Training IOU:0.2778, Validation BCE loss:1.0066, Validation Dice:0.0179, Validation IOU:0.2728\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:45<00:00,  2.00it/s, loss=0.992, iou=0.281, dice=0.0273]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.68it/s, loss=0.982, iou=0.232, dice=0.032]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [5/50], Training BCE loss:0.9922, Training DICE:0.0273, Training IOU:0.2811, Validation BCE loss:0.9825, Validation Dice:0.0320, Validation IOU:0.2317\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:45<00:00,  2.00it/s, loss=0.963, iou=0.291, dice=0.0504]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.69it/s, loss=0.951, iou=0.315, dice=0.0576]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [6/50], Training BCE loss:0.9625, Training DICE:0.0504, Training IOU:0.2910, Validation BCE loss:0.9515, Validation Dice:0.0576, Validation IOU:0.3147\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:46<00:00,  2.00it/s, loss=0.92, iou=0.327, dice=0.0934]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.68it/s, loss=0.905, iou=0.309, dice=0.104]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [7/50], Training BCE loss:0.9199, Training DICE:0.0934, Training IOU:0.3272, Validation BCE loss:0.9050, Validation Dice:0.1038, Validation IOU:0.3086\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:45<00:00,  2.00it/s, loss=0.855, iou=0.375, dice=0.167]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.68it/s, loss=0.835, iou=0.431, dice=0.179]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [8/50], Training BCE loss:0.8551, Training DICE:0.1666, Training IOU:0.3751, Validation BCE loss:0.8350, Validation Dice:0.1786, Validation IOU:0.4310\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:46<00:00,  2.00it/s, loss=0.762, iou=0.431, dice=0.277]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.68it/s, loss=0.735, iou=0.436, dice=0.287]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [9/50], Training BCE loss:0.7619, Training DICE:0.2771, Training IOU:0.4312, Validation BCE loss:0.7352, Validation Dice:0.2875, Validation IOU:0.4358\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:47<00:00,  2.00it/s, loss=0.654, iou=0.478, dice=0.403]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.68it/s, loss=0.649, iou=0.441, dice=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [10/50], Training BCE loss:0.6540, Training DICE:0.4026, Training IOU:0.4785, Validation BCE loss:0.6492, Validation Dice:0.3823, Validation IOU:0.4415\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:47<00:00,  2.00it/s, loss=0.554, iou=0.505, dice=0.511]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.68it/s, loss=0.583, iou=0.443, dice=0.456]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [11/50], Training BCE loss:0.5545, Training DICE:0.5108, Training IOU:0.5054, Validation BCE loss:0.5831, Validation Dice:0.4556, Validation IOU:0.4425\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:49<00:00,  2.00it/s, loss=0.482, iou=0.527, dice=0.587]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.67it/s, loss=0.531, iou=0.427, dice=0.506]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [12/50], Training BCE loss:0.4819, Training DICE:0.5866, Training IOU:0.5269, Validation BCE loss:0.5306, Validation Dice:0.5063, Validation IOU:0.4273\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:49<00:00,  2.00it/s, loss=0.438, iou=0.534, dice=0.626]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.68it/s, loss=0.478, iou=0.475, dice=0.566]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [13/50], Training BCE loss:0.4382, Training DICE:0.6256, Training IOU:0.5339, Validation BCE loss:0.4784, Validation Dice:0.5661, Validation IOU:0.4746\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:47<00:00,  2.00it/s, loss=0.413, iou=0.541, dice=0.647]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.67it/s, loss=0.461, iou=0.478, dice=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [14/50], Training BCE loss:0.4125, Training DICE:0.6472, Training IOU:0.5413, Validation BCE loss:0.4605, Validation Dice:0.5832, Validation IOU:0.4776\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:47<00:00,  2.00it/s, loss=0.394, iou=0.546, dice=0.659]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.67it/s, loss=0.438, iou=0.497, dice=0.606]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [15/50], Training BCE loss:0.3943, Training DICE:0.6593, Training IOU:0.5457, Validation BCE loss:0.4382, Validation Dice:0.6061, Validation IOU:0.4974\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:46<00:00,  2.00it/s, loss=0.383, iou=0.556, dice=0.672]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.67it/s, loss=0.443, iou=0.483, dice=0.598]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [16/50], Training BCE loss:0.3829, Training DICE:0.6723, Training IOU:0.5556, Validation BCE loss:0.4432, Validation Dice:0.5984, Validation IOU:0.4829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:46<00:00,  2.00it/s, loss=0.375, iou=0.564, dice=0.682]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.67it/s, loss=0.436, iou=0.488, dice=0.607]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [17/50], Training BCE loss:0.3748, Training DICE:0.6824, Training IOU:0.5642, Validation BCE loss:0.4360, Validation Dice:0.6065, Validation IOU:0.4878\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:47<00:00,  2.00it/s, loss=0.367, iou=0.566, dice=0.685]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.67it/s, loss=0.454, iou=0.476, dice=0.593]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [18/50], Training BCE loss:0.3674, Training DICE:0.6855, Training IOU:0.5660, Validation BCE loss:0.4538, Validation Dice:0.5931, Validation IOU:0.4759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:48<00:00,  2.00it/s, loss=0.364, iou=0.571, dice=0.69]\n",
            "100%|██████████| 1392/1392 [03:29<00:00,  6.65it/s, loss=0.459, iou=0.471, dice=0.586]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [19/50], Training BCE loss:0.3637, Training DICE:0.6901, Training IOU:0.5705, Validation BCE loss:0.4591, Validation Dice:0.5865, Validation IOU:0.4706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:49<00:00,  2.00it/s, loss=0.355, iou=0.574, dice=0.692]\n",
            "100%|██████████| 1392/1392 [03:29<00:00,  6.65it/s, loss=0.43, iou=0.487, dice=0.607]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [20/50], Training BCE loss:0.3555, Training DICE:0.6919, Training IOU:0.5736, Validation BCE loss:0.4295, Validation Dice:0.6069, Validation IOU:0.4874\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:51<00:00,  2.00it/s, loss=0.35, iou=0.581, dice=0.699]\n",
            "100%|██████████| 1392/1392 [03:29<00:00,  6.65it/s, loss=0.436, iou=0.492, dice=0.608]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [21/50], Training BCE loss:0.3502, Training DICE:0.6989, Training IOU:0.5810, Validation BCE loss:0.4358, Validation Dice:0.6084, Validation IOU:0.4917\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:51<00:00,  2.00it/s, loss=0.348, iou=0.587, dice=0.704]\n",
            "100%|██████████| 1392/1392 [03:28<00:00,  6.66it/s, loss=0.486, iou=0.463, dice=0.569]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [22/50], Training BCE loss:0.3477, Training DICE:0.7043, Training IOU:0.5873, Validation BCE loss:0.4861, Validation Dice:0.5686, Validation IOU:0.4628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:50<00:00,  2.00it/s, loss=0.345, iou=0.587, dice=0.706]\n",
            "100%|██████████| 1392/1392 [03:29<00:00,  6.64it/s, loss=0.418, iou=0.514, dice=0.627]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [23/50], Training BCE loss:0.3450, Training DICE:0.7060, Training IOU:0.5871, Validation BCE loss:0.4181, Validation Dice:0.6274, Validation IOU:0.5135\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:50<00:00,  2.00it/s, loss=0.337, iou=0.592, dice=0.71]\n",
            "100%|██████████| 1392/1392 [03:29<00:00,  6.64it/s, loss=0.432, iou=0.505, dice=0.619]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [24/50], Training BCE loss:0.3373, Training DICE:0.7099, Training IOU:0.5919, Validation BCE loss:0.4320, Validation Dice:0.6187, Validation IOU:0.5045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:51<00:00,  2.00it/s, loss=0.336, iou=0.593, dice=0.71]\n",
            "100%|██████████| 1392/1392 [03:29<00:00,  6.63it/s, loss=0.417, iou=0.516, dice=0.631]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [25/50], Training BCE loss:0.3363, Training DICE:0.7098, Training IOU:0.5925, Validation BCE loss:0.4167, Validation Dice:0.6312, Validation IOU:0.5156\n",
            "=> saved best model as validation DICE is greater than previous best DICE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:51<00:00,  2.00it/s, loss=0.33, iou=0.601, dice=0.718]\n",
            "100%|██████████| 1392/1392 [03:29<00:00,  6.64it/s, loss=0.429, iou=0.513, dice=0.624]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [26/50], Training BCE loss:0.3297, Training DICE:0.7177, Training IOU:0.6009, Validation BCE loss:0.4293, Validation Dice:0.6241, Validation IOU:0.5132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:52<00:00,  1.99it/s, loss=0.326, iou=0.608, dice=0.725]\n",
            "100%|██████████| 1392/1392 [03:29<00:00,  6.64it/s, loss=0.475, iou=0.483, dice=0.587]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [27/50], Training BCE loss:0.3258, Training DICE:0.7251, Training IOU:0.6084, Validation BCE loss:0.4755, Validation Dice:0.5875, Validation IOU:0.4831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:52<00:00,  1.99it/s, loss=0.32, iou=0.609, dice=0.725]\n",
            "100%|██████████| 1392/1392 [03:29<00:00,  6.64it/s, loss=0.426, iou=0.506, dice=0.619]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [28/50], Training BCE loss:0.3195, Training DICE:0.7249, Training IOU:0.6090, Validation BCE loss:0.4261, Validation Dice:0.6190, Validation IOU:0.5060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:53<00:00,  1.99it/s, loss=0.318, iou=0.612, dice=0.727]\n",
            "100%|██████████| 1392/1392 [03:29<00:00,  6.64it/s, loss=0.412, iou=0.51, dice=0.627]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [29/50], Training BCE loss:0.3181, Training DICE:0.7271, Training IOU:0.6115, Validation BCE loss:0.4121, Validation Dice:0.6275, Validation IOU:0.5105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4174/4174 [34:52<00:00,  1.99it/s, loss=0.315, iou=0.613, dice=0.728]\n",
            "100%|██████████| 1392/1392 [03:29<00:00,  6.64it/s, loss=0.425, iou=0.519, dice=0.629]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch [30/50], Training BCE loss:0.3155, Training DICE:0.7283, Training IOU:0.6128, Validation BCE loss:0.4253, Validation Dice:0.6286, Validation IOU:0.5185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 1842/4174 [15:23<19:26,  2.00it/s, loss=0.305, iou=0.625, dice=0.741]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import yaml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import ndimage as ndi\n",
        "from scipy.ndimage import label, generate_binary_structure\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "def save_output(output,output_directory,test_image_paths,counter):\n",
        "  # This saves the predicted image into a directory. The naming convention will follow PI\n",
        "  for i in range(output.shape[0]):\n",
        "      label = test_image_paths[counter][-23:]\n",
        "      label = label.replace('NI','PD')\n",
        "      np.save(output_directory+'/'+label,output[i,:,:])\n",
        "      #print(\"SAVED\",output_directory+label+'.npy')\n",
        "      counter+=1\n",
        "\n",
        "  return counter\n",
        "\n",
        "def calculate_fp(prediction_dir,mask_dir,distance_threshold=80):\n",
        "  \"\"\"This calculates the fp by comparing the predicted mask and orginal mask\"\"\"\n",
        "  #TP,TN,FP,FN\n",
        "  #FN will always be zero here as all the mask contains a nodule\n",
        "  confusion_matrix =[0,0,0,0]\n",
        "  # This binary structure enables the function to recognize diagnoally connected label as same nodule.\n",
        "  s = generate_binary_structure(2,2)\n",
        "  print('Length of prediction dir is ',len(os.listdir(prediction_dir)))\n",
        "  for prediction in os.listdir(prediction_dir):\n",
        "      #print(confusion_matrix)\n",
        "      mask_id = prediction.replace('PD','MA')\n",
        "      mask = np.load(mask_dir+'/'+mask_id)\n",
        "      predict = np.load(prediction_dir+'/'+prediction)\n",
        "      answer_com = np.array(ndi.center_of_mass(mask))\n",
        "      # Patience is used to check if the patch has cropped the same image\n",
        "      patience =0\n",
        "      labeled_array, nf = label(predict, structure=s)\n",
        "      if nf>0:\n",
        "          for n in range(nf):\n",
        "              lab=np.array(labeled_array)\n",
        "              lab[lab!=(n+1)]=0\n",
        "              lab[lab==(n+1)]=1\n",
        "              predict_com=np.array(ndi.center_of_mass(labeled_array))\n",
        "              if np.linalg.norm(predict_com-answer_com,2) < distance_threshold:\n",
        "                  patience +=1\n",
        "              else:\n",
        "                  confusion_matrix[2]+=1\n",
        "          if patience > 0:\n",
        "              # Add to True Positive\n",
        "              confusion_matrix[0]+=1\n",
        "          else:\n",
        "              # Add to False Negative\n",
        "              # if the patience remains 0, and nf >0, it means that the slice contains both the TN and FP\n",
        "              confusion_matrix[3]+=1\n",
        "\n",
        "      else:\n",
        "          # Add False Negative since the UNET didn't detect a cancer even when there was one\n",
        "          confusion_matrix[3]+=1\n",
        "  return np.array(confusion_matrix)"
      ],
      "metadata": {
        "id": "D7gklmOiQQQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = 'UNET_PLUS_AUGMENTATION'\n",
        "print('-'*20)\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "print(\"=> creating model {}\".format(NAME))\n",
        "\n",
        "model = NestedUNet(num_classes=1)\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model)\n",
        "print(\"Loading model file from {}\".format(NAME))\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/data/output/model_outputs/{}/model.pth'.format(NAME)))\n",
        "model = model.cuda()\n",
        "IMAGE_DIR = '/content/drive/MyDrive/data/Nodule_data/image/'\n",
        "MASK_DIR = '/content/drive/MyDrive/data/Nodule_data/mask/'\n",
        "\n",
        "meta = pd.read_csv('/content/drive/MyDrive/data/Nodule_data/meta/meta.csv')\n",
        "meta['original_image']= meta['original_image'].apply(lambda x:IMAGE_DIR+ x +'.npy')\n",
        "meta['mask_image'] = meta['mask_image'].apply(lambda x:MASK_DIR+ x +'.npy')\n",
        "test_meta = meta[meta['data_split']=='Test']\n",
        "\n",
        "# Get all *npy images into list for Test(True Positive Set)\n",
        "test_image_paths = list(test_meta['original_image'])\n",
        "test_mask_paths = list(test_meta['mask_image'])\n",
        "\n",
        "total_patients = len(test_meta.groupby('patient_id'))\n",
        "\n",
        "print(\"*\"*50)\n",
        "print(\"The lentgh of image: {}, mask folders: {} for test\".format(len(test_image_paths),len(test_mask_paths)))\n",
        "print(\"Total patient number is :{}\".format(total_patients))\n",
        "\n",
        "OUTPUT_MASK_DIR = '/content/drive/MyDrive/data/Segmentation/{}'.format(NAME)\n",
        "print(\"Saving OUTPUT files in directory {}\".format(OUTPUT_MASK_DIR))\n",
        "os.makedirs(OUTPUT_MASK_DIR,exist_ok=True)\n",
        "test_dataset = MyLidcDataset(test_image_paths, test_mask_paths)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=False,\n",
        "    pin_memory=True,\n",
        "    drop_last=False,\n",
        "    num_workers=2)\n",
        "\n",
        "model.eval()\n",
        "print(\" \")\n",
        "print(\"Printing the first 5 image directories...\",test_image_paths[:5])\n",
        "print(\"Printing the first 5 mask directories...\",test_mask_paths[:5])\n",
        "\n",
        "avg_meters = {'iou': AverageMeter(),\n",
        "              'dice': AverageMeter()}\n",
        "with torch.no_grad():\n",
        "  counter = 0\n",
        "  pbar = tqdm(total=len(test_loader))\n",
        "  for input, target in test_loader:\n",
        "    input = input.cuda()\n",
        "    target = target.cuda()\n",
        "\n",
        "    output = model(input)\n",
        "    iou = iou_score(output, target)\n",
        "    dice = dice_coef2(output, target)\n",
        "\n",
        "    avg_meters['iou'].update(iou, input.size(0))\n",
        "    avg_meters['dice'].update(dice, input.size(0))\n",
        "\n",
        "    postfix = OrderedDict([\n",
        "        ('iou', avg_meters['iou'].avg),\n",
        "        ('dice',avg_meters['dice'].avg)\n",
        "    ])\n",
        "\n",
        "    output = torch.sigmoid(output)\n",
        "    output = (output>0.5).float().cpu().numpy()\n",
        "    output = np.squeeze(output,axis=1)\n",
        "    #print(output.shape)\n",
        "\n",
        "    counter = save_output(output,OUTPUT_MASK_DIR,test_image_paths,counter)\n",
        "    pbar.set_postfix(postfix)\n",
        "    pbar.update(1)\n",
        "  pbar.close()\n",
        "  print(\"=\"*50)\n",
        "\n",
        "print('IoU: {:.4f}'.format(avg_meters['iou'].avg))\n",
        "print('DICE:{:.4f}'.format(avg_meters['dice'].avg))\n",
        "\n",
        "confusion_matrix = calculate_fp(OUTPUT_MASK_DIR ,MASK_DIR,distance_threshold=80)\n",
        "print(\"=\"*50)\n",
        "print(\"TP: {} FP:{}\".format(confusion_matrix[0],confusion_matrix[2]))\n",
        "print(\"FN: {} TN:{}\".format(confusion_matrix[3],confusion_matrix[1]))\n",
        "print(\"{:2f} FP/per Scan \".format(confusion_matrix[2]/total_patients))\n",
        "print(\"=\"*50)\n",
        "print(\" \")\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ljRqKmqeQZnl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c675fe1e-fe48-4df4-fb41-82d4294d4344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------\n",
            "=> creating model UNET_PLUS_AUGMENTATION\n",
            "Loading model file from UNET_PLUS_AUGMENTATION\n",
            "**************************************************\n",
            "The lentgh of image: 2784, mask folders: 2784 for test\n",
            "Total patient number is :717\n",
            "Saving OUTPUT files in directory /content/drive/MyDrive/data/Segmentation/UNET_PLUS_AUGMENTATION\n",
            " \n",
            "Printing the first 5 image directories... ['/content/drive/MyDrive/data/Nodule_data/image/0001_NI000_slice002.npy', '/content/drive/MyDrive/data/Nodule_data/image/0002_NI000_slice005.npy', '/content/drive/MyDrive/data/Nodule_data/image/0002_NI000_slice008.npy', '/content/drive/MyDrive/data/Nodule_data/image/0002_NI000_slice015.npy', '/content/drive/MyDrive/data/Nodule_data/image/0002_NI000_slice019.npy']\n",
            "Printing the first 5 mask directories... ['/content/drive/MyDrive/data/Nodule_data/mask/0001_MA000_slice002.npy', '/content/drive/MyDrive/data/Nodule_data/mask/0002_MA000_slice005.npy', '/content/drive/MyDrive/data/Nodule_data/mask/0002_MA000_slice008.npy', '/content/drive/MyDrive/data/Nodule_data/mask/0002_MA000_slice015.npy', '/content/drive/MyDrive/data/Nodule_data/mask/0002_MA000_slice019.npy']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1392/1392 [36:28<00:00,  1.57s/it, iou=0.513, dice=0.627]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "IoU: 0.5126\n",
            "DICE:0.6268\n",
            "Length of prediction dir is  2784\n",
            "==================================================\n",
            "TP: 1786 FP:1374\n",
            "FN: 998 TN:0\n",
            "1.916318 FP/per Scan \n",
            "==================================================\n",
            " \n"
          ]
        }
      ]
    }
  ]
}